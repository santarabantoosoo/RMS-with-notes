<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1_intro</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="1_intro_files/libs/clipboard/clipboard.min.js"></script>
<script src="1_intro_files/libs/quarto-html/quarto.js"></script>
<script src="1_intro_files/libs/quarto-html/popper.min.js"></script>
<script src="1_intro_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="1_intro_files/libs/quarto-html/anchor.min.js"></script>
<link href="1_intro_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="1_intro_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="1_intro_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="1_intro_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="1_intro_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="1_intro_files/libs/quarto-diagram/mermaid.min.js"></script>
<script src="1_intro_files/libs/quarto-diagram/mermaid-init.js"></script>
<link href="1_intro_files/libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">1_intro</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="sec-intro" class="level1 page-columns page-full">
<h1>Introduction</h1>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class=""><a href="https://youtu.be/IiJ6pMs2BiA"><img src="movie.png" width="25"></a></span></div></div>
<section id="sec-intro-tep" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-intro-tep">Hypothesis Testing, Estimation, and Prediction</h2>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-1">flowchart LR
uses[Uses of models] --&gt; test[Hypothesis testing]
uses --&gt; estimat[Estimation]
uses --&gt; pred[Prediction]
test --&gt; ftest["Formal tests&lt;br&gt;Formal model&lt;br&gt;comparison&lt;br&gt;(e.g. AIC)"]
estimat --&gt; festimat[Point and interval&lt;br&gt;estimation of one&lt;br&gt;predictor's effect]
pred --&gt; fpred[Estimated outcome&lt;br&gt;or outcome&lt;br&gt;tendency for&lt;br&gt;a subject]
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<!-- 1-sample t-test and Wilcoxon signed-rank added 2023-07-28 -->
<p>Even when only testing <span class="math inline">\(H_{0}\)</span> a model based approach has advantages:</p>
<ul>
<li><p>Permutation and rank tests not as useful for estimation </p></li>
<li><p><strong>hamza: Permutation tests, also known as randomization tests or exact tests, are inference methods to test hypothesis significance by comparing observed data to a distribution of permuted or randomized data. These tests are particularly useful when the assumptions of traditional parametric tests, such as normality or independence, are violated, or when the sample size is small. The test is then called permutation/randomization t-test or permutation/randomization ANOVA for example. Procedure: compare observed test statistic to a distribution of test statistics generated from permutation of data. I think it’s similar to bootstrapping but using permutation instead of sampling with replacement. Rank tests are like Mann whitney or kruskal wallis</strong></p></li>
<li><p>Cannot readily be extended to cluster sampling or repeated measurements</p></li>
<li><p>Models generalize tests</p>
<ul>
<li><p>2-sample <span class="math inline">\(t\)</span>-test, ANOVA <span class="math inline">\(\rightarrow\)</span> <br> multiple linear regression</p>
<p><strong>hamza from video: t-test and ANOVA are special cases of regression. Maybe it’s better to learn the general case instead of learning a bunch of special cases. Andy field supports this idea in his book DSUR.</strong></p></li>
<li><p>paired <span class="math inline">\(t\)</span>-test <span class="math inline">\(\rightarrow\)</span> <br> linear regression with fixed effects for subjects (block on subjects); linear mixed model with random per-subject intercepts</p></li>
<li><p>Wilcoxon, Kruskal-Wallis, Spearman <span class="math inline">\(\rightarrow\)</span> <br> proportional odds (PO) ordinal logistic model</p></li>
<li><p>Wilcoxon signed-rank test <span class="math inline">\(\rightarrow\)</span> <br> replace with <a href="https://hbiostat.org/bbr/nonpar.html#sec-nonpar-rd">rank-difference test</a> <span class="math inline">\(\rightarrow\)</span> <br> PO model blocking on subject; ordinal mixed model</p></li>
<li><p>log-rank <span class="math inline">\(\rightarrow\)</span> Cox</p>
<p><strong>hamza from video: sometimes you read a paper stating that proportional odds assumption is not valid, so we used log rank instead of cox. That’s a silly argument, as long rank is a special case of cox and still needs the PH assumption.</strong></p></li>
</ul></li>
<li><p>Models not only allow for multiplicity adjustment but for shrinkage of estimates</p></li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">A</span></span></div><p><strong>hamza from video: how shrinkage of estimates? if you are using random effects model or using shrinkage or penalized maximum likelihood estimates, that’s actually shrinking estimates, probably towards a common grand mean. For example, reporting mortality statistics across 100s of hospital may increase the accuracy of the estimate. I think this means that a penalized regression like lasso can have a lot of predictors and it can exclude some of them to allow for a more accurate estimate without overfitting</strong></p>
<ul>
<li>Statisticians comfortable with <span class="math inline">\(P\)</span>-value adjustment but fail to recognize that the difference between the most different treatments is badly biased.</li>
</ul>
<p><strong>hamza: I think this is related to ranking all test results and compare the top and bottom. These two points are biased because they were obtained after ranking. i.e.&nbsp;they are not occuring by chance. I think this example will come back later.</strong></p>
<p>Statistical estimation is usually model-based</p>
<ul>
<li>Relative effect of increasing cholesterol from 200 to 250  mg/dl on hazard of death, holding other risk factors constant</li>
<li>Adjustment depends on how other risk factors relate to hazard</li>
<li>Usually interested in adjusted (partial) effects, not unadjusted (marginal or crude) effects</li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">B</span></span></div></section>
<section id="examples-of-uses-of-predictive-multivariable-modeling" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="examples-of-uses-of-predictive-multivariable-modeling">Examples of Uses of Predictive Multivariable Modeling</h2>
<ul>
<li>Financial performance, consumer purchasing, loan pay-back </li>
<li>Ecology</li>
<li>Product life</li>
<li>Employment discrimination</li>
<li>Medicine, epidemiology, health services research</li>
<li>Probability of diagnosis, time course of a disease</li>
<li>Checking that a previously developed summary index (e.g., BMI) adequately summarizes its component variables</li>
<li>Developing new summary indexes by how variables predict an outcome</li>
<li>Comparing non-randomized treatments</li>
<li>Getting the correct estimate of relative effects in randomized studies requires covariable adjustment if model is nonlinear
<ul>
<li>Crude odds ratios biased towards 1.0 if sample heterogeneous</li>
</ul></li>
<li>Estimating absolute treatment effect (e.g., risk difference)
<ul>
<li>Use e.g.&nbsp;difference in two predicted probabilities</li>
</ul></li>
<li>Cost-effectiveness ratios
<ul>
<li>incremental cost / incremental <em>ABSOLUTE</em> benefit</li>
<li>most studies use avg. cost difference / avg. benefit, which may apply to no one</li>
</ul></li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">C</span></span></div></section>
<section id="misunderstandings-about-prediction-vs.-classification" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="misunderstandings-about-prediction-vs.-classification">Misunderstandings about Prediction vs.&nbsp;Classification</h2>

<div class="no-row-height column-margin column-container"><div class="">
<audio controls="">
<source src="http://hbiostat.org/audio/rms/classification.mp3" data-external="1" type="audio/mpeg">

</audio>
<p><a href="https://fharrell.com/post/classification">Classification vs.&nbsp;Prediction</a></p>
</div></div><div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-2">flowchart LR
goal[Goal] --&gt; predest[Estimation or Prediction]
goal --&gt; classif[Classification]
predest --&gt; whatpre[Continuous output&lt;br&gt;&lt;br&gt;Handles close&lt;br&gt;calls and&lt;br&gt;gray zones&lt;br&gt;&lt;br&gt;Provides input to&lt;br&gt;decision maker]
classif --&gt; whatclass[Categorical output&lt;br&gt;&lt;br&gt;Hides close calls&lt;br&gt;&lt;br&gt;Makes premature&lt;br&gt;decisions&lt;br&gt;&lt;br&gt;Does not provide&lt;br&gt;sufficient input&lt;br&gt;to decision maker&lt;br&gt;&lt;br&gt;Useful for quick&lt;br&gt;easy decisions or&lt;br&gt;when outcome&lt;br&gt;probabilities are&lt;br&gt;near 0 and 1]
</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<ul>
<li>Many analysts desire to develop “classifiers” instead of  predictions</li>
<li>Outside of, for example, visual or sound pattern recognition, classification represents a premature decision</li>
<li>See <a href="http://fharrell.com/post/classification">this blog</a> for details</li>
<li>Suppose that</li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">D</span></span></div><ol type="1">
<li>response variable is binary</li>
<li>the two levels represent a sharp dichotomy with no gray zone (e.g., complete success vs.&nbsp;total failure with no possibility of a partial success)</li>
<li>one is forced to assign (classify) future observations to only these two choices</li>
<li>the cost of misclassification is the same for every future observation, and the ratio of the cost of a false positive to the cost of a false negative equals the (often hidden) ratio implied by the analyst’s classification rule</li>
</ol>
<ul>
<li>Then classification is <strong>still sub-optimal</strong> for driving the development of a predictive instrument as well as for hypothesis testing and estimation</li>
<li>Classification and its associated classification accuracy measure—the proportion classified “correctly”—are very sensitive to the relative frequencies of the outcome variable. If a classifier is applied to another dataset with a different outcome prevalence, the classifier may no longer apply.</li>
<li>Far better is to use the full information in the data to develop a probability model, then develop classification rules on the basis of estimated probabilities
<ul>
<li><span class="math inline">\(\uparrow\)</span> power, <span class="math inline">\(\uparrow\)</span> precision, <span class="math inline">\(\uparrow\)</span> decision making</li>
</ul></li>
<li>Classification is more problematic if response variable is ordinal or continuous or the groups are not truly distinct (e.g., disease or no disease when severity of disease is on a continuum); dichotomizing it up front for the analysis is not appropriate
<ul>
<li><em>minimum</em> loss of information (when dichotomization is at the median) is large</li>
<li>may require the sample size to increase many–fold to compensate for loss of information <span class="citation" data-cites="fed09con">@fed09con</span></li>
</ul></li>
<li>Two-group classification represents artificial forced choice
<ul>
<li>best option may be “no choice, get more data”</li>
</ul></li>
<li>Unlike prediction (e.g., of absolute risk), classification implicitly uses utility (loss; cost of false positive or false negative) functions </li>
<li>Hidden problems:
<ul>
<li>Utility function depends on variables not collected (subjects’ preferences) that are available only at the decision point</li>
<li>Assumes every subject has the same utility function</li>
<li>Assumes this function coincides with the analyst’s</li>
</ul></li>
<li>Formal decision analysis uses
<ul>
<li>optimum predictions using all available data</li>
<li>subject-specific utilities, which are often based on variables not predictive of the outcome</li>
</ul></li>
<li>ROC analysis is misleading except for the special case of mass one-time group decision making with unknowable utilities<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><a href="https://youtu.be/1yYrDVN_AYc"><img src="movie.png" width="25"></a></span></div><p>See <span class="citation" data-cites="vic08dec">@vic08dec</span>, <span class="citation" data-cites="bri08ski">@bri08ski</span>, <span class="citation" data-cites="gai05cri">@gai05cri</span>, <span class="citation" data-cites="bor07sta">@bor07sta</span>, <span class="citation" data-cites="fan07amn">@fan07amn</span>, <span class="citation" data-cites="gne07str">@gne07str</span>.</p>
<div class="page-columns page-full"><p>Accuracy score used to drive model building should be a continuous score that utilizes all of the information in the data. </p><div class="no-row-height column-margin column-container"><span class=""><a href="https://youtu.be/FDTwEZ3KcyA"><img src="movie.png" width="25"></a></span></div></div>
<p>In summary:</p>
<ul>
<li>Classification is a forced choice — a decision. </li>
<li>Decisions require knowledge of the cost or utility of making an incorrect decision.</li>
<li>Predictions are made without knowledge of utilities.</li>
<li>A prediction can lead to better decisions than classification. For example suppose that one has an estimate of the risk of an event, <span class="math inline">\(\hat{P}\)</span>. One might make a decision if <span class="math inline">\(\hat{P} &lt; 0.10\)</span> or <span class="math inline">\(\hat{P} &gt; 0.90\)</span> in some situations, even without knowledge of utilities. If on the other hand <span class="math inline">\(\hat{P} = 0.6\)</span> or the confidence interval for <span class="math inline">\(P\)</span> is wide, one might
<ul>
<li>make no decision and instead opt to collect more data</li>
<li>make a tentative decision that is revisited later</li>
<li>make a decision using other considerations such as the infusion of new resources that allow targeting a larger number of potential customers in a marketing campaign</li>
</ul></li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">E</span></span></div><p><strong>The Dichotomizing Motorist</strong></p>
<ul>
<li>The speed limit is 60. </li>
<li>I am going faster than the speed limit.</li>
<li>Will I be caught?</li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">F</span></span></div><p>An answer by a dichotomizer:</p>
<ul>
<li>Are you going faster than 70? </li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">G</span></span></div><p>An answer from a better dichotomizer:</p>
<ul>
<li>If you are among other cars, are you going faster than 73? </li>
<li>If you are exposed are your going faster than 67?</li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">H</span></span></div><p>Better:</p>
<ul>
<li>How fast are you going and are you exposed? </li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">I</span></span></div><p>Analogy to most medical diagnosis research in which +/- diagnosis is a false dichotomy of an underlying disease severity:</p>
<ul>
<li>The speed limit is moderately high. </li>
<li>I am going fairly fast.</li>
<li>Will I be caught?</li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">J</span></span></div></section>
<section id="planning-for-modeling" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="planning-for-modeling">Planning for Modeling</h2>
<div class="page-columns page-full"><p> </p><div class="no-row-height column-margin column-container"><span class=""><audio controls=""><source src="http://hbiostat.org/audio/rms/planning.mp3" data-external="1" type="audio/mpeg"></audio></span><span class=""><span style="color:red">K</span></span></div></div>
<ul>
<li>Chance that predictive model will be used (<span class="citation" data-cites="rei06tra">@rei06tra</span>)</li>
<li>Response definition, follow-up</li>
<li>Variable definitions</li>
<li>Observer variability</li>
<li>Missing data</li>
<li>Preference for continuous variables</li>
<li>Subjects</li>
<li>Sites <!-- * See @lau97cli---></li>
</ul>
<p>What can keep a sample of data from being appropriate for modeling:</p>
<ol type="1">
<li>Most important predictor or response variables not collected </li>
<li>Subjects in the dataset are ill-defined or not representative of the population to which inferences are needed</li>
<li>Data collection sites do not represent the population of sites</li>
<li>Key variables missing in large numbers of subjects</li>
<li>Data not missing at random</li>
<li>No operational definitions for key variables and/or measurement errors severe</li>
<li>No observer variability studies done</li>
</ol>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">L</span></span></div><p>What else can go wrong in modeling?</p>
<ol type="1">
<li>The process generating the data is not stable. </li>
<li>The model is misspecified with regard to nonlinearities or interactions, or there are predictors missing.</li>
<li>The model is misspecified in terms of the transformation of the response variable or the model’s distributional assumptions.</li>
<li>The model contains discontinuities (e.g., by categorizing continuous predictors or fitting regression shapes with sudden changes) that can be gamed by users.</li>
<li>Correlations among subjects are not specified, or the correlation structure is misspecified, resulting in inefficient parameter estimates and overconfident inference.</li>
<li>The model is overfitted, resulting in predictions that are too extreme or positive associations that are false.</li>
<li>The user of the model relies on predictions obtained by extrapolating to combinations of predictor values well outside the range of the dataset used to develop the model.</li>
<li>Accurate and discriminating predictions can lead to behavior changes that make future predictions inaccurate.</li>
</ol>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">M</span></span></div><p><span class="citation" data-cites="iez94ris">@iez94ris</span> lists these dimensions to capture, for patient outcome studies:</p>
<ol type="1">
<li>age </li>
<li>sex</li>
<li>acute clinical stability</li>
<li>principal diagnosis</li>
<li>severity of principal diagnosis</li>
<li>extent and severity of comorbidities</li>
<li>physical functional status</li>
<li>psychological, cognitive, and psychosocial functioning</li>
<li>cultural, ethnic, and socioeconomic attributes and behaviors</li>
<li>health status and quality of life</li>
<li>patient attitudes and preferences for outcomes</li>
</ol>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">N</span></span></div><p>General aspects to capture in the predictors:</p>
<ol type="1">
<li>baseline measurement of response variable </li>
<li>current status</li>
<li>trajectory as of time zero, or past levels of a key variable</li>
<li>variables explaining much of the variation in the response</li>
<li>more subtle predictors whose distributions strongly differ between levels of the key variable of interest in an observational study</li>
</ol>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">O</span></span></div></section>
<section id="choice-of-the-model" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="choice-of-the-model">Choice of the Model</h2>
<ul>
<li>In biostatistics and epidemiology and most other areas we  usually choose model empirically</li>
<li>Model must use data efficiently</li>
<li>Should model overall structure (e.g., acute vs.&nbsp;chronic)</li>
<li>Robust models are better</li>
<li>Should have correct mathematical structure (e.g., constraints on probabilities)</li>
</ul>
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">P</span></span></div></section>
<section id="model-uncertainty-data-driven-model-specification" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="model-uncertainty-data-driven-model-specification">Model uncertainty / Data-driven Model Specification</h2>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class=""><audio controls=""><source src="http://hbiostat.org/audio/rms/uncertainty.mp3" data-external="1" type="audio/mpeg"></audio></span></div></div>
<div class="cell page-columns page-full" data-fig-width="8">
<div class="cell-output-display column-screen-inset-right">
<div>
<p>

</p><pre class="mermaid mermaid-js" data-tooltip-selector="#mermaid-tooltip-3">flowchart LR
ms[Model Selection] --&gt; pre[Pre-specified] --&gt; eps[Try to specify&lt;br&gt;a model flexible&lt;br&gt;enough to fit&lt;br&gt;&lt;br&gt;Fit assumed&lt;br&gt;to be adequate&lt;br&gt;&lt;br&gt;Need not be perfect&lt;br&gt;but as good as&lt;br&gt;any model not&lt;br&gt;requiring larger N] --&gt; nomu[No model&lt;br&gt;uncertainty,&lt;br&gt;accurate statistical&lt;br&gt;inference]
ms --&gt; bayes[Pre-specified&lt;br&gt;Bayesian model&lt;br&gt;with parameters&lt;br&gt;capturing departures&lt;br&gt;from simplicity] --&gt; bac[No binary model&lt;br&gt;choices required] --&gt; api[Accurate posterior&lt;br&gt;inference&lt;br&gt;&lt;br&gt;Robust&lt;br&gt;&lt;br&gt;Insights about&lt;br&gt;non-normality etc.]
ms --&gt; cont[Contest between&lt;br&gt;desired and&lt;br&gt;more general model] --&gt; pair[Check if more&lt;br&gt;general model is&lt;br&gt;better for the money] --&gt; mmu[Better way to&lt;br&gt;check goodness&lt;br&gt;of fit&lt;br&gt;&lt;br&gt;Minimal model&lt;br&gt;uncertainty]
ms --&gt; emp[Empirical] --&gt; gof[Goodness-of-fit&lt;br&gt;checking if&lt;br&gt;involves &gt;2&lt;br&gt; pre-specified&lt;br&gt;models] --&gt; dist
emp --&gt; empus[May be highly&lt;br&gt;unstable if&lt;br&gt;entertain many&lt;br&gt;models or do&lt;br&gt;feature&lt;br&gt;selection] --&gt; dist[Distorted statistical&lt;br&gt;inference]
ms --&gt; ml[Machine learning] --&gt; mluns[May be highly&lt;br&gt;unstable&lt;br&gt;unless N huge] --&gt; noinf[No statistical inference]
</pre>
<div id="mermaid-tooltip-3" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<ul>
<li><p>Standard errors, C.L., <span class="math inline">\(P\)</span>-values, <span class="math inline">\(R^2\)</span> wrong if computed as  if the model pre-specified</p></li>
<li><p>Stepwise variable selection is widely used and abused</p></li>
<li><p>Bootstrap can be used to repeat all analysis steps to properly penalize variances, etc.</p></li>
<li><p><span class="citation" data-cites="ye98mea">@ye98mea</span>: “generalized degrees of freedom” (GDF) for any “data mining” or model selection procedure based on least squares</p>
<ul>
<li>Example: 20 candidate predictors, <span class="math inline">\(n=22\)</span>, forward stepwise, best 5-variable model: GDF=14.1</li>
<li>Example: CART, 10 candidate predictors, <span class="math inline">\(n=100\)</span>, 19 nodes: GDF=76</li>
</ul></li>
<li><p>See <span class="citation" data-cites="luo06tun">@luo06tun</span> for an approach involving adding noise to <span class="math inline">\(Y\)</span> to improve variable selection</p></li>
<li><p>Another example: <span class="math inline">\(t\)</span>-test to compare two means <!-- NEW --></p>
<ul>
<li><p>Basic test assumes equal variance and normal data distribution</p></li>
<li><p>Typically examine the two sample distributions to decide whether to transform <span class="math inline">\(Y\)</span> or switch to a different test</p></li>
<li><p>Examine the two SDs to decide whether to use the standard test or switch to a Welch <span class="math inline">\(t\)</span>-test</p></li>
<li><p>Final confidence interval for mean difference is conditional on the final choices being correct</p></li>
<li><p>Ignores model uncertainty</p></li>
<li><p>Confidence interval will not have the claimed coverage</p></li>
<li><p>Get proper coverage by adding parameters for what you don’t know</p>
<ul>
<li>Bayesian <span class="math inline">\(t\)</span>-test: parameters for variance ratio and for d.f. of a <span class="math inline">\(t\)</span>-distribution for the raw data (allows heavy tails)</li>
</ul></li>
</ul></li>
</ul>
<!-- NEW 2022-10-28 -->
<div class="no-row-height column-margin column-container"><span class=""><span style="color:red">Q</span></span></div><section id="sec-intro-gof" class="level3">
<h3 class="anchored" data-anchor-id="sec-intro-gof">Model Uncertainty and Model Checking</h3>
<p>As the Bayesian <span class="math inline">\(t\)</span>-test exemplifies, there are advantages of a continuous approach to modeling instead of engaging in dichotomous goodness-of-fit (GOF) assessments. Some general comments:</p>
<ul>
<li>In a frequentist setting, GOF checking can inflate type I assertion probability <span class="math inline">\(\alpha\)</span> and make confidence intervals falsely narrow. In a Bayesian setting, posterior distributions and resulting uncertainty intervals can be too narrow.</li>
<li>Rather than accepting or not accepting a proposed model on the basis of a GOF assessment, embed the proposed model inside a more general model that relaxes the assumptions, and use AIC or a formal test to decide between the two. Comparing only two pre-specified models will result in minimal model uncertainty.
<ul>
<li>More general model could include nonlinear terms and interactions</li>
<li>It could also relax distributional assumptions, as done with the non-normality parameter in the Bayesian <span class="math inline">\(t\)</span>-test</li>
<li>Often the sample size is not large enough to allow model assumptions to be relaxed without overfitting; AIC assesses whether additional complexities are “good for the money”. If a more complex model results in worse predictions due to overfitting, it is doubtful that such a model should be used for inference.</li>
</ul></li>
<li>Instead of focusing on model assumption checking, focus on the <a href="https://fharrell.com/post/impactpo"><em>impact</em> of making those assumptions</a>, using for example comparison of adjusted <span class="math inline">\(R^2\)</span> measures and bootstrap confidence intervals for differences in predicted values from two models.</li>
<li>In many situations you can use a <a href="https://fharrell.com/post/rpo">semiparametric model</a> that makes many fewer assumptions than a parametric model</li>
<li>See <a href="https://stats.stackexchange.com/questions/551264">this</a> for more in-depth discussion</li>
</ul>
</section>
</section>
<section id="study-questions" class="level2">
<h2 class="anchored" data-anchor-id="study-questions">Study Questions</h2>
<ol type="1">
<li>Can you estimate the effect of increasing age from 21 to 30 without a statistical model?</li>
<li>What is an example where machine learning users have used “classification” in the wrong sense?</li>
<li>When is classification (in the proper sense) an appropriate goal?</li>
<li>Why are so many decisions non-binary?</li>
<li>How do we normally choose statistical models—from subject matter theory or empirically?</li>
<li>What is model uncertainty?</li>
<li>An investigator feels that there are too many variables to analyze so she uses significance testing to select which variables to analyze further. What is wrong with that?</li>
</ol>
<p>Copyright 2023, Frank E Harrell Jr</p>
<p>License</p>
</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>To make an optimal decision you need to know all relevant data about an individual (used to estimate the probability of an outcome), and the utility (cost, loss function) of making each decision. Sensitivity and specificity do not provide this information. For example, if one estimated that the probability of a disease given age, sex, and symptoms is 0.1 and the “cost”of a false positive equaled the “cost” of a false negative, one would act as if the person does not have the disease. Given other utilities, one would make different decisions. If the utilities are unknown, one gives the best estimate of the probability of the outcome to the decision maker and let her incorporate her own unspoken utilities in making an optimum decision for her. <br><br>Besides the fact that cutoffs do not apply to individuals, only to groups, individual decision making does not utilize sensitivity and specificity. For an individual we can compute <span class="math inline">\(\textrm{Prob}(Y=1 | X=x)\)</span>; we don’t care about <span class="math inline">\(\textrm{Prob}(Y=1 | X&gt;c)\)</span>, and an individual having <span class="math inline">\(X=x\)</span> would be quite puzzled if she were given <span class="math inline">\(\textrm{Prob}(X&gt;c | \textrm{future unknown Y})\)</span> when she already knows <span class="math inline">\(X=x\)</span> so <span class="math inline">\(X\)</span> is no longer a random variable. <br><br>Even when group decision making is needed, sensitivity and specificity can be bypassed. For mass marketing, for example, one can rank order individuals by the estimated probability of buying the product, to create a lift curve. This is then used to target the <span class="math inline">\(k\)</span> most likely buyers where <span class="math inline">\(k\)</span> is chosen to meet total program cost constraints.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>